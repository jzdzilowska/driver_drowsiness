{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10079118,"sourceType":"datasetVersion","datasetId":6213409}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Driver Drowsiness Detection System","metadata":{}},{"cell_type":"markdown","source":"Studies indicate that fatigue-related crashes account for about 20% of road accidents and even more on roads with no driving hour regulations. Driver detection systems, particularly those focusing on drowsiness detection, aim to address that alarming rate by monitoring drivers for signs of drowsiness and issuing timely alerts to prevent potential crashes.\n\nFor our final project, we chose to develop a DDS by using the UTA Real-Life Drowsiness Dataset, which features diverse participants and comprehensive data. We will train a convolutional neural network (CNN) to analyze facial, eye, and mouth movements at different stages of drowsiness. The model will provide warnings and alerts based on the detected level of fatigue, with accuracy tests ensuring its reliability.","metadata":{}},{"cell_type":"markdown","source":"### Requirements \n● TensorFlow: Developed by the Google Brain team for machine learning and artificial intelligence, Tensorflow has a allows for training and inference of deep neural networks.\n\n● Keras: Provides a Python interface for artificial neural networks (inbuilt python library).\n\n● Numpy: Used for scientific computing in Python. Provides support for arrays, matrices, and various mathematical functions to operate on them. \n\n● OpenCV: Machine learning and compiter vision library; contains >2500 algorhitms optimized for various CV tasks \n\n● Scikit-learn: Data mining, data analysis. In this project, used for splitting datasets. \n\n● Pandas: Data manipulation and analysis library. Used to create dataframes associating frames with their labels.","metadata":{}},{"cell_type":"code","source":"# Importing required libraries\nimport numpy as np \nimport pandas as pd \nimport tensorflow as tg\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:41:49.280282Z","iopub.execute_input":"2024-12-04T11:41:49.280953Z","iopub.status.idle":"2024-12-04T11:42:05.787206Z","shell.execute_reply.started":"2024-12-04T11:41:49.280910Z","shell.execute_reply":"2024-12-04T11:42:05.786103Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Frame - Class (Label) Association\nFrames captured are associated with \"not drowsy\", \"neutral\", and \"drowsy\" classes, based on the 'vid' label within the parsed filename. They're later saved to a pandas dataframe for training, validating, and testing. ","metadata":{}},{"cell_type":"code","source":"def parse_filename(filename):\n    parts = filename.split('_')\n    for i, part in enumerate(parts):\n        if part.lower() == 'vid':\n            label = int(parts[i + 1])\n            if label == 0:\n                return 'not_drowsy'\n            elif label == 5:\n                return 'neutral'\n            elif label == 10:\n                return 'drowsy'\n            else:\n                return None\n    return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:42:05.789259Z","iopub.execute_input":"2024-12-04T11:42:05.789863Z","iopub.status.idle":"2024-12-04T11:42:05.796754Z","shell.execute_reply.started":"2024-12-04T11:42:05.789826Z","shell.execute_reply":"2024-12-04T11:42:05.795501Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# ! Universalize the working directory\nworking_directory = '/kaggle/input/drowsy-driver-imagesonly/Drowsey Driver Images'\n\ndef create_dataframe(image_dir):\n    data = []\n    for root, dirs, files in os.walk(image_dir):\n        for file in files:\n            if file.endswith('.jpg'):\n                label = parse_filename(file)\n                if label:\n                    data.append((os.path.join(root, file), label))\n    return pd.DataFrame(data, columns=['filepath', 'label'])\n\ndf = create_dataframe(working_directory)\nprint(df.head(50))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:42:05.798445Z","iopub.execute_input":"2024-12-04T11:42:05.798772Z","iopub.status.idle":"2024-12-04T11:42:09.415393Z","shell.execute_reply.started":"2024-12-04T11:42:05.798744Z","shell.execute_reply":"2024-12-04T11:42:09.414185Z"}},"outputs":[{"name":"stdout","text":"                                             filepath       label\n0   /kaggle/input/drowsy-driver-imagesonly/Drowsey...     neutral\n1   /kaggle/input/drowsy-driver-imagesonly/Drowsey...  not_drowsy\n2   /kaggle/input/drowsy-driver-imagesonly/Drowsey...     neutral\n3   /kaggle/input/drowsy-driver-imagesonly/Drowsey...     neutral\n4   /kaggle/input/drowsy-driver-imagesonly/Drowsey...      drowsy\n5   /kaggle/input/drowsy-driver-imagesonly/Drowsey...      drowsy\n6   /kaggle/input/drowsy-driver-imagesonly/Drowsey...     neutral\n7   /kaggle/input/drowsy-driver-imagesonly/Drowsey...     neutral\n8   /kaggle/input/drowsy-driver-imagesonly/Drowsey...  not_drowsy\n9   /kaggle/input/drowsy-driver-imagesonly/Drowsey...     neutral\n10  /kaggle/input/drowsy-driver-imagesonly/Drowsey...      drowsy\n11  /kaggle/input/drowsy-driver-imagesonly/Drowsey...      drowsy\n12  /kaggle/input/drowsy-driver-imagesonly/Drowsey...     neutral\n13  /kaggle/input/drowsy-driver-imagesonly/Drowsey...     neutral\n14  /kaggle/input/drowsy-driver-imagesonly/Drowsey...     neutral\n15  /kaggle/input/drowsy-driver-imagesonly/Drowsey...     neutral\n16  /kaggle/input/drowsy-driver-imagesonly/Drowsey...  not_drowsy\n17  /kaggle/input/drowsy-driver-imagesonly/Drowsey...  not_drowsy\n18  /kaggle/input/drowsy-driver-imagesonly/Drowsey...     neutral\n19  /kaggle/input/drowsy-driver-imagesonly/Drowsey...      drowsy\n20  /kaggle/input/drowsy-driver-imagesonly/Drowsey...  not_drowsy\n21  /kaggle/input/drowsy-driver-imagesonly/Drowsey...      drowsy\n22  /kaggle/input/drowsy-driver-imagesonly/Drowsey...     neutral\n23  /kaggle/input/drowsy-driver-imagesonly/Drowsey...  not_drowsy\n24  /kaggle/input/drowsy-driver-imagesonly/Drowsey...     neutral\n25  /kaggle/input/drowsy-driver-imagesonly/Drowsey...      drowsy\n26  /kaggle/input/drowsy-driver-imagesonly/Drowsey...     neutral\n27  /kaggle/input/drowsy-driver-imagesonly/Drowsey...      drowsy\n28  /kaggle/input/drowsy-driver-imagesonly/Drowsey...  not_drowsy\n29  /kaggle/input/drowsy-driver-imagesonly/Drowsey...      drowsy\n30  /kaggle/input/drowsy-driver-imagesonly/Drowsey...      drowsy\n31  /kaggle/input/drowsy-driver-imagesonly/Drowsey...      drowsy\n32  /kaggle/input/drowsy-driver-imagesonly/Drowsey...  not_drowsy\n33  /kaggle/input/drowsy-driver-imagesonly/Drowsey...  not_drowsy\n34  /kaggle/input/drowsy-driver-imagesonly/Drowsey...  not_drowsy\n35  /kaggle/input/drowsy-driver-imagesonly/Drowsey...     neutral\n36  /kaggle/input/drowsy-driver-imagesonly/Drowsey...  not_drowsy\n37  /kaggle/input/drowsy-driver-imagesonly/Drowsey...      drowsy\n38  /kaggle/input/drowsy-driver-imagesonly/Drowsey...      drowsy\n39  /kaggle/input/drowsy-driver-imagesonly/Drowsey...     neutral\n40  /kaggle/input/drowsy-driver-imagesonly/Drowsey...     neutral\n41  /kaggle/input/drowsy-driver-imagesonly/Drowsey...      drowsy\n42  /kaggle/input/drowsy-driver-imagesonly/Drowsey...      drowsy\n43  /kaggle/input/drowsy-driver-imagesonly/Drowsey...     neutral\n44  /kaggle/input/drowsy-driver-imagesonly/Drowsey...     neutral\n45  /kaggle/input/drowsy-driver-imagesonly/Drowsey...     neutral\n46  /kaggle/input/drowsy-driver-imagesonly/Drowsey...  not_drowsy\n47  /kaggle/input/drowsy-driver-imagesonly/Drowsey...  not_drowsy\n48  /kaggle/input/drowsy-driver-imagesonly/Drowsey...     neutral\n49  /kaggle/input/drowsy-driver-imagesonly/Drowsey...     neutral\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"df.sample(frac = 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:42:09.417981Z","iopub.execute_input":"2024-12-04T11:42:09.418298Z","iopub.status.idle":"2024-12-04T11:42:09.438974Z","shell.execute_reply.started":"2024-12-04T11:42:09.418269Z","shell.execute_reply":"2024-12-04T11:42:09.437751Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                               filepath       label\n372   /kaggle/input/drowsy-driver-imagesonly/Drowsey...      drowsy\n4491  /kaggle/input/drowsy-driver-imagesonly/Drowsey...  not_drowsy\n1398  /kaggle/input/drowsy-driver-imagesonly/Drowsey...      drowsy\n4637  /kaggle/input/drowsy-driver-imagesonly/Drowsey...      drowsy\n3747  /kaggle/input/drowsy-driver-imagesonly/Drowsey...     neutral\n...                                                 ...         ...\n5687  /kaggle/input/drowsy-driver-imagesonly/Drowsey...      drowsy\n5074  /kaggle/input/drowsy-driver-imagesonly/Drowsey...      drowsy\n1035  /kaggle/input/drowsy-driver-imagesonly/Drowsey...     neutral\n3036  /kaggle/input/drowsy-driver-imagesonly/Drowsey...      drowsy\n4841  /kaggle/input/drowsy-driver-imagesonly/Drowsey...  not_drowsy\n\n[5750 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filepath</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>372</th>\n      <td>/kaggle/input/drowsy-driver-imagesonly/Drowsey...</td>\n      <td>drowsy</td>\n    </tr>\n    <tr>\n      <th>4491</th>\n      <td>/kaggle/input/drowsy-driver-imagesonly/Drowsey...</td>\n      <td>not_drowsy</td>\n    </tr>\n    <tr>\n      <th>1398</th>\n      <td>/kaggle/input/drowsy-driver-imagesonly/Drowsey...</td>\n      <td>drowsy</td>\n    </tr>\n    <tr>\n      <th>4637</th>\n      <td>/kaggle/input/drowsy-driver-imagesonly/Drowsey...</td>\n      <td>drowsy</td>\n    </tr>\n    <tr>\n      <th>3747</th>\n      <td>/kaggle/input/drowsy-driver-imagesonly/Drowsey...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5687</th>\n      <td>/kaggle/input/drowsy-driver-imagesonly/Drowsey...</td>\n      <td>drowsy</td>\n    </tr>\n    <tr>\n      <th>5074</th>\n      <td>/kaggle/input/drowsy-driver-imagesonly/Drowsey...</td>\n      <td>drowsy</td>\n    </tr>\n    <tr>\n      <th>1035</th>\n      <td>/kaggle/input/drowsy-driver-imagesonly/Drowsey...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>3036</th>\n      <td>/kaggle/input/drowsy-driver-imagesonly/Drowsey...</td>\n      <td>drowsy</td>\n    </tr>\n    <tr>\n      <th>4841</th>\n      <td>/kaggle/input/drowsy-driver-imagesonly/Drowsey...</td>\n      <td>not_drowsy</td>\n    </tr>\n  </tbody>\n</table>\n<p>5750 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"## Data Preparation and Augmentation\nThe dataset is split into training, validation, and testing sets. The frames are then rescaled, as well as augmented for the training dataset to increase the variety of data. ","metadata":{}},{"cell_type":"code","source":"# Initialization of the train, validation, and test datasets extracted from the UTA RealLife Drowsiness Dataset. \ntrain_val_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\ntrain_df, val_df = train_test_split(train_val_df, test_size=0.25, stratify=train_val_df['label'], random_state=42)\n\ntrain_datagen = ImageDataGenerator(rescale=0.2)\nval_datagen = ImageDataGenerator(rescale=0.2)\ntest_datagen = ImageDataGenerator(rescale=0.2)\n\n# Artificially increases size of the training dataset; ensures a wider range of imgs. \ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df,\n    x_col='filepath',\n    y_col='label',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical'\n)\n\nval_generator = val_datagen.flow_from_dataframe(\n    val_df,\n    x_col='filepath',\n    y_col='label',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical'\n)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    test_df,\n    x_col='filepath',\n    y_col='label',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:42:09.440239Z","iopub.execute_input":"2024-12-04T11:42:09.440520Z","iopub.status.idle":"2024-12-04T11:42:10.492056Z","shell.execute_reply.started":"2024-12-04T11:42:09.440491Z","shell.execute_reply":"2024-12-04T11:42:10.491250Z"}},"outputs":[{"name":"stdout","text":"Found 3450 validated image filenames belonging to 3 classes.\nFound 1150 validated image filenames belonging to 3 classes.\nFound 1150 validated image filenames belonging to 3 classes.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Model Definition, Compilation, and Training\nThe model architecture is defined using a pre-trained (on ImageNet) VGG16 base model. The top layers are excluded and the input shape is specified to match the dimensions of our input data. Custom layers are then added for the 3-class classification. To prevent the weights of the pre-trained VGG16 base model from being updated during training, we freeze all the layers of the base model, after which the model is compiled, and trained using the training and validation datasets. ","metadata":{}},{"cell_type":"code","source":"base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\nx = base_model.output\nx = Flatten()(x)\nx = Dense(128, activation='relu')(x)\npredictions = Dense(3, activation='softmax')(x)  # 3 classes: 0 - not_drowsy, 5 - drowsy, 10 - neutral\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# The base is freezed\nfor layer in base_model.layers:\n    layer.trainable = False\n\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# ! Actual training\nmodel.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n    validation_data=val_generator,\n    validation_steps=val_generator.samples // val_generator.batch_size,\n    epochs=5\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:42:10.493375Z","iopub.execute_input":"2024-12-04T11:42:10.493764Z","iopub.status.idle":"2024-12-04T12:47:52.036098Z","shell.execute_reply.started":"2024-12-04T11:42:10.493719Z","shell.execute_reply":"2024-12-04T12:47:52.034888Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1306s\u001b[0m 12s/step - accuracy: 0.8289 - loss: 2.2893 - val_accuracy: 0.9804 - val_loss: 0.0505\nEpoch 2/5\n\u001b[1m  1/107\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16:43\u001b[0m 9s/step - accuracy: 0.9375 - loss: 0.1057","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 78ms/step - accuracy: 0.9375 - loss: 0.1057 - val_accuracy: 1.0000 - val_loss: 0.0026\nEpoch 3/5\n\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1299s\u001b[0m 12s/step - accuracy: 0.9941 - loss: 0.0165 - val_accuracy: 0.9848 - val_loss: 0.0326\nEpoch 4/5\n\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 6.4003e-04 - val_accuracy: 1.0000 - val_loss: 0.0027\nEpoch 5/5\n\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1296s\u001b[0m 12s/step - accuracy: 0.9984 - loss: 0.0048 - val_accuracy: 0.9911 - val_loss: 0.0263\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7b6c9c94c4c0>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"model.save_weights('drowsiness_detection_weights.weights.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T12:47:52.037541Z","iopub.execute_input":"2024-12-04T12:47:52.037859Z","iopub.status.idle":"2024-12-04T12:47:52.210514Z","shell.execute_reply.started":"2024-12-04T12:47:52.037830Z","shell.execute_reply":"2024-12-04T12:47:52.209618Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Performance evaluation\nObtained results: 0.0897449404001236 test loss, 0.9937499761581421 test accuracy","metadata":{}},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\nprint(f'Test loss: {test_loss}')\nprint(f'Test accuracy: {test_accuracy}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T12:47:52.211651Z","iopub.execute_input":"2024-12-04T12:47:52.211972Z","iopub.status.idle":"2024-12-04T12:53:15.257534Z","shell.execute_reply.started":"2024-12-04T12:47:52.211942Z","shell.execute_reply":"2024-12-04T12:53:15.256305Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 9s/step - accuracy: 0.9866 - loss: 0.0303\nTest loss: 0.0258723646402359\nTest accuracy: 0.9883928298950195\n","output_type":"stream"}],"execution_count":8}]}